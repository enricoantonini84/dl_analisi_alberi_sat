\chapter{Analysis of results}In the previous chapters, different algorithms have been treated that allow, starting from satellite images, to derive the position of the trees both as coordinates in pixels and geographical, finally exporting a GeoJSON that defines in a more or less precise way the shape of the crown or the bounding box that delimits the tree itself. Other algorithms, such as SegFormer and DetecTree, are instead able to isolate groups of trees.\\These two modes are interesting as they are applicable for calculating the indicator dealt with in chapter 7, where both the distance from individual trees and the distance from parks or planted green areas is considered.\\However, in order to verify which of the models achieved the best results, it is necessary first of all to identify the real geographical position of the trees present on the urban fabric.\section{Ground Truth Dataset}To proceed with the verification it is essential to be able to access a dataset containing the position in latitude and longitude of the planted trees, in other words our ground truth, or the verified reference data. Otherwise it is impossible to compare the accuracy of the various models seen previously, which are based only on visual detection.\subsection{Access to public databases}In some cases the region, municipality or third-party entities provide APIs or datasets that map trees and/or plantings. When this type of information is easily accessible, the process of building the ground truth database is greatly simplified, since it is already available as validated and clean data, i.e. filtered by possible false positives or false negatives.\\It is necessary, however, to consider that the trees mapped in these datasets, could contain only the areas and trees that make up the vegetation on public soil, therefore not considering private planted properties that are detected instead by satellite images alone.\\The format of the data varies by public body, region or municipality: in some cases the simple coordinates are provided in JSON/CSV, in others in GeoJSON ready to be imported into GIS applications, in others they are in the form of a CHM package. The latter is a particular format that is generated by LIDAR (Light Detection and Ranging) sensors placed on aircraft that generate, thanks to laser pulse technology, a 3D representation of the territory and the crowns of the trees.\subsection{Manual Annotation}Another alternative is to create a dataset manually, with applications such as QGIS, importing the reference satellite image and annotating the coordinates in a point and click on a layer, later exportable to GeoJSON.\\This solution makes it possible to annotate all trees, on public and non-public land, but it is extremely time-consuming. It is also crucial to verify that the satellite image used in the software (e.g. a GeoTIFF file) is correctly georeferenced, since an incorrect georeference would result in an inaccurate annotation of the geographical coordinates of each tree detected.\section{Templates Benchmark}Once the ground truth is defined, it is possible to proceed to the comparison with the predictions generated by the models: according to the source of the data it is necessary to establish the comparison parameters on which to calculate the detection quality metrics.\\A GeoJSON made available by the municipality of Milan was used for this analysis\cite{ComuneMilanoAlberiGeolocalizzazione2024}, which maps all the trees planted on public land within the municipal boundaries. For reasons of cost and computational complexity, the detection was carried out on the satellite map measuring 3km radius from the center of Milan. Data is freely available under the Creative Commons license\\

\subsection{Requirements}As previously mentioned, this GeoJSON from an institutional source exclusively includes trees on public areas, excluding those on private land. It is therefore not possible to accurately determine actual false positives, as numerous trees absent from the municipal dataset may have been detected correctly by previously analyzed models, thus creating an overestimation of detection errors.\\In addition, the data provided by the municipality map trees as single georeferenced points instead of as polygons so, to make this comparison possible, a tree is considered correctly detected when the georeferenced point falls within a YOLO bounding box or segmentation polygon (which represents the canopy for DetecTree2 or the planted area for SegFormer). Trees whose points do not fall into any polygon are classified as undetected.\\To properly compare models, however, it is necessary to distinguish between those that identify individual trees (such as YOLO and DetecTree2) and those that identify larger areas, such as plant areas or green areas (SegFormer). This distinction is crucial since different detection approaches require different assessment methodologies.\subsection{Model Parameters}The results are based on detections made with the following confidence parameters:\begin{itemize}
    \item YOLO11: 0.416, which as defined by the F1 curve after training is the value that perfectly balances precision and recall. To compensate for the accuracy of the detection, an 11m proximity buffer is applied around the bounding boxes.\item Detectree2: 0.25, defined for a detection that favors higher recall values but reduces missed detection.\item SegFormer: 0.30, offers the best balance between precision and recall, detected after a number of tests (SegFormer does not have a global F1 value, it works at the pixel level with probability per class).\item DetecTree: has no confidence parameterization, it also performs a pixel classification, but in a different way from SegFormer.\end{itemize}

\subsection{Detection Script}The comparison function between the GeoJSON file of the municipality of Milan, used as ground truth, and the polygons predicted by the models is relatively simple and linear:\begin{lstlisting}
import geopandas as gpd

def calculateTreeCoverage(groundTruthPath: str, modelTreesDetectedPath: str):
    trees = gpd.read_file(groundTruthPath)
    detections = gpd.read_file(modelTreesDetectedPath)
    detectedTrees = set()
    
    for _, polygon in detections.iterrows():
        treesInside = trees[polygon.geometry.contains(trees.geometry)]
        detectedTrees.update(treesInside.index)
    
    coveragePercentage = (len(detectedTrees) / len(trees)) * 100
\end{lstlisting}

\noindent In the first two lines, files are loaded into two GeoPandas dataframes, a Python library that allows data to be processed in tables and csv, with support for geospatial data management and analysis\cite{kelsey_jordahl_2020_3946761}.\\After initializing a set to contain the actual trees detected, the data is crossed: for each polygon detected by the machine learning model, the geometric operation is used\textit{contains()}, which isolates all ground truth trees contained within the detection range. The indices of these trees are then added to the set\textit{DetectTrees}.\\At this point the detection percentage is nothing more than the ratio of unique trees detected to the total of trees in the ground truth.\section{Tree area detection}In this case there are two algorithms that return areas populated by trees, instead of single crowns: for completeness DetecTree was included.\subsection{SegFormer}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Detected trees & 25,029\\
Undetected trees& 19,365\\
Polygons with trees & 4,076\\
Polygons without trees & 9,202\\
\hline
\textbf{Detected trees percentage} & \textbf{56.38\% }\\
\hline
\end{tabular}
\caption{SegFormer detection results}
\end{table}

\noindent SegFormer is very effective at detecting trees in urban settings and, considering that the starting dataset is the same as the one used for training the YOLO11 model, is significantly more precise when we consider the coverage area instead of the individual trees, demonstrating good selectivity in detecting actually planted areas.\subsection{DetecTree}
\begin{table}[H]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Detected trees & 17,563\\
Undetected trees& 27,294\\
Polygons with trees & 8,006\\
Polygons without trees & 436,865\\
\hline
\textbf{Detected trees percentage} & \textbf{39.2\%}\\
\hline
\end{tabular}
\caption{DetecTree detection results}
\end{table}

\noindent DetecTree is confirmed to be able to detect the majority of trees but, as introduced in the dedicated chapter, for tree cover alone it is extremely imprecise because it mixes the crowns with the green areas. To demonstrate this, there is precisely the fact that green areas divided into more than 400 thousand polygons have been identified by the algorithm; of these, only 1.8\% contain trees: certainly some polygons will contain plantings in private areas, but the majority will contain generic "urban green".\section{Detecting individual trees}Let's now see the results on the data inferred by the two object detection models, which exploit convolutional networks: as previously mentioned they work on the features/characteristics of the image, to be able to isolate the objects in them.\subsection{YOLO11}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Detected trees & 22,956\\
Undetected trees& 21,438\\
Polygons with trees & 10,817\\
Polygons without trees & 11,861\\
Average trees per polygon & 2.62\\
\hline
\textbf{Detected trees percentage} & \textbf{51.71\%}\\
\hline
\end{tabular}
\caption{YOLO11 detection results}
\end{table}

\noindent In this case the polygons are derived from the bounding boxes which, being designed to highlight the detected object, do not constitute the actual crown of the tree.\\Considering only the trees present in the GeoJSON of Milan, we have an average of 2.62 trees per detection: i.e. 24.2\% of the bounding boxes contain a single tree, while 71.0\% contain small groups of 2 to 5 trees, demonstrating good accuracy in the detection of individual trees and small groups.\subsection{DetecTree2}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Detected trees & 10,355\\
Undetected trees& 34,039\\
Polygons with trees & 5,216\\
Polygons without trees & 9,659\\
Average trees per polygon & 2.01\\
\hline
\textbf{Detected trees percentage} & \textbf{23.33\%}\\
\hline
\end{tabular}
\caption{DetecTree2 detection results}
\end{table}

\noindent DetecTree2 is a complicated model to balance, as at low confidence values it is able to detect more trees but introduces an important number of false positives. At this confidence value, identified as good after various inference tests on satellite images, it seems to be significantly less effective than the other two: probably the fact of being in an urban context does not help it, in fact it seems to be much more suitable for forests or forest ecosystems\cite{Ball2022DetectTree2Documentation}.\\Considering the trees it was able to successfully detect, we can still notice an average of 2.01 trees per polygon; thus DetecTree2 shows a good ability to segment single crowns: 49.3\% of the polygons contain a single tree and 47.1\% contain small groups of 2 to 5 trees.\subsection{SegFormer + Watershed}Watershed is an image segmentation technique that allows you to separate connected objects. It has been applied to the results of SegFormer to attempt to subdivide tree areas into individual trees.\\

\begin{table}[H]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Detected trees & 24,280\\
Undetected trees& 20,114\\
Polygons with trees & 1,917\\
Polygons without trees & 1,845\\
Average trees per polygon & 13.87\\
\hline
\textbf{Detected trees percentage} & \textbf{54.69\%}\\
\hline
\end{tabular}
\caption{SegFormer + Watershed detection results}
\end{table}

\noindent Watershed application to SegFormer results slightly worsens performance: detection rate drops from 56.38\% to 54.69\%. This suggests that attempting to further subdivide the detected areas may introduce some errors.\\With an average of 13.87 trees per polygon, the SegFormer + Watershed algorithm mainly detects areas with tree groups: only 5.6\% of the polygons contain a single tree, while 39.9\% contain groups of more than 10 trees.\section{Comparative comparison}The models analyzed show distinctive features depending on their architecture and detection approach.\subsection{Detecting Single Trees}For the detection of individual trees, the models with the best performance in terms of precision are:\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Algorithm} & \textbf{Coverage} & \textbf{Trees per polygon}\\
\hline
YOLO11 & 51.71\% & 2.62\\
DetecTree2 & 23.33\% & 2.01\\
SegFormer+Watershed & 54.69\% & 13.87\\
\hline
\end{tabular}
\caption{Comparison of algorithms for single tree detection}
\end{table}

\noindent YOLO11 and DetecTree2 are distinguished by their ability to identify individual trees (average ~2-3 trees per detection), with DetecTree2 particularly precise in the segmentation of single crowns (49.3\% detection with only one tree). YOLO11 with an 11m buffer achieves a detection rate of 51.71\% while maintaining an average of 2.62 trees per detection, making it very effective for individual tree detection. SegFormer+Watershed, despite having a slightly higher detection rate (54.69\%), mainly identifies groups of trees (average 13.87 trees/detection), making it less suitable for applications that require precise counting of individual trees.\subsection{Tree area detection}To identify planted areas and tree groups, SegFormer base is the most effective:\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Algorithm} & \textbf{Detection rate} \\
\hline
SegFormer & 56.38\%\\
DetecTree & 39.2\% \\
\hline
\end{tabular}
\caption{Comparison of algorithms for tree area detection}
\end{table}

\noindent SegFormer offers the best detection rate (56.38\%) with its ability to accurately identify tree groups, while DetecTree has an excessive false positive rate (98.19\%), which makes it unsuitable for practical tree detection-only applications.\section{Analysis and improvements}The results achieved by the various models denote a decent ability to detect trees: SegFormer, the best performing model among the three, detects just under 57\%of the trees planted on the municipal territory. This is a significant percentage for this specific task, notoriously complex given the need for high-quality satellite imagery to achieve good detection levels. The most common factors that can compromise results are related to the quality of the training dataset and the type of input images used for inference.\\

\subsection{Species of trees in the Lleida dataset}The dataset used for training the two models that returned the best feedback in terms of coverage comes from studies conducted in the urban area of Lleida, Spain, previously introduced in the chapter dedicated to YOLO. The documentation on the tree species of the territory of Lleida\cite{paeria_lleida_especies_arbories}highlights the presence of some species typical of the Mediterranean and river environment, some of which may not be fully representative of the Milanese urban ecosystem.\\The climatic and biogeographical difference between Lleida and Milan could influence the effectiveness of the model trained on this dataset when applied to the Lombard context, characterized by a temperate continental climate and a different urban tree composition.\subsection{Proximity buffer}As we have seen, a model like SegFormer is able to give an acceptable result in terms of detection. In order to further improve performance, there is a methodology applicable in the post-processing phase, which consists of implementing a proximity buffer around existing surveys\cite{zhang2018proximity}.\\To evaluate whether to apply a buffer on the detection carried out by SegFormer, that is, the most performing, it is necessary to identify the problem: the 74.0\%of the missed trees is within 50m from the already mapped detections, so they are visually present but not detected due to:\\

\begin{itemize}
    \item Shades masking trees, caused by the time satellite images were taken.\item Edges of the crowns where segmentation stops prematurely.\item Overlays between adjacent trees that confuse the neural network.\end{itemize}

\noindent By detecting a tree at a given location, it is statistically likely that there are other trees in its vicinity that the model has not seen: the buffer helps to recover false negatives.\\The results with this spatial post-processing procedure manage to detect 38,304 trees compared to 25,029, bringing the detection rate of trees in the Milan municipal territory to 86.28\%.\\

\subsection{Performance Assessment}This detection approach using deep learning + spatial post-processing, which achieves 86.28\% tree detection, far exceeds acceptable standards for urban tree detection (typically 60-80\%) and should be considered an excellent result for several reasons:

\begin{itemize}
    \item High urban density with complex overlaps between buildings and vegetation.
    \item Diversity of tree species with varying morphologies.
    \item Urban shadows and occlusions due to city architecture.
    \item Intensive pruning that modifies the natural shapes of the crowns.
\end{itemize}

\noindent
Manual verification work is reduced to 13.72\% of the total dataset, representing significant time and resource savings for urban forest management applications.